import requests
from bs4 import BeautifulSoup
import pandas as pd

# --- éƒ¨å“ï¼ˆé–¢æ•°ï¼‰ã®å®šç¾©ã‚¨ãƒªã‚¢ ---

def get_soup(target_url):
    """
    æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰HTMLã‚’å–å¾—ã—ã€BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™é–¢æ•°
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124"
    }
    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    response = requests.get(target_url, headers=headers)
    # è§£ææº–å‚™
    soup = BeautifulSoup(response.text, "html.parser")
    return soup

def extract_python_news(soup):
    """
    BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰Pythonãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ½å‡ºã—ã€ãƒªã‚¹ãƒˆã§è¿”ã™é–¢æ•°
    """
    data_list = []
    news_widget = soup.find("div", class_="blog-widget")

    if news_widget:
        news_items = news_widget.find_all("li")
        for item in news_items:
            title = item.find("a").text
            link = item.find("a")["href"]
            full_url = f"https://www.python.org{link}"
            
            # è¾æ›¸ã«ã¾ã¨ã‚ã‚‹
            data = {
                "Title": title,
                "URL": full_url
            }
            data_list.append(data)
            
    return data_list

def save_to_csv(data_list, filename):
    """
    ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹é–¢æ•°
    """
    if not data_list:
        print("âš ï¸ ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # DataFrameã«å¤‰æ›
    df = pd.DataFrame(data_list)
    # ä¿å­˜
    df.to_csv(filename, index=False, encoding="utf-8_sig")
    print(f"ğŸ’¾ '{filename}' ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼(ä»¶æ•°: {len(df)}ä»¶)")

# --- å®Ÿè¡Œã‚¨ãƒªã‚¢ï¼ˆãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼‰ ---

def main():
    print("ğŸš€ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒœãƒƒãƒˆèµ·å‹• (Functionç‰ˆ)")
    
    # 1. è¨­å®š
    target_url = "https://www.python.org/"
    output_file = "python_news_v2.csv"
    
    # 2. å–å¾— (æ‹…å½“A)
    print(f"ğŸ“¡ {target_url} ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")
    soup_data = get_soup(target_url)
    
    # 3. æŠ½å‡º (æ‹…å½“B)
    print("ğŸ” ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ½å‡ºä¸­...")
    news_data = extract_python_news(soup_data)
    
    # 4. ä¿å­˜ (æ‹…å½“C)
    save_to_csv(news_data, output_file)
    
    print("âœ… å…¨å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸã¨ãã ã‘ main() ã‚’å‹•ã‹ã™ãŠã¾ã˜ãªã„
if __name__ == "__main__":
    main()